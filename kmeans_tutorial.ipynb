{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# K-Means Clustering Tutorial üéØ\n",
    "\n",
    "This notebook provides a complete implementation and tutorial of the K-Means clustering algorithm from scratch.\n",
    "\n",
    "## What you'll learn:\n",
    "- How K-Means algorithm works step by step\n",
    "- Implementation from scratch in Python\n",
    "- Visualization of clustering results\n",
    "- How to use the algorithm for predictions\n",
    "\n",
    "**Perfect for Google Colab!** Just run each cell sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## üì¶ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Set up matplotlib for better plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\" Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "algorithm"
   },
   "source": [
    "## üßÆ K-Means Algorithm Implementation\n",
    "\n",
    "Let's implement K-Means from scratch to understand how it works internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmeans_class"
   },
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    \"\"\"K-Means clustering algorithm implementation from scratch.\"\"\"\n",
    "\n",
    "    def __init__(self, k: int, max_iters: int = 100, random_state: int = None):\n",
    "        \"\"\"\n",
    "        Initialize K-Means clustering.\n",
    "\n",
    "        Args:\n",
    "            k: Number of clusters\n",
    "            max_iters: Maximum number of iterations\n",
    "            random_state: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X: np.ndarray) -> 'KMeans':\n",
    "        \"\"\"\n",
    "        Fit K-Means to the data.\n",
    "\n",
    "        Args:\n",
    "            X: Data points of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            self: Fitted KMeans object\n",
    "        \"\"\"\n",
    "        if self.random_state:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Step 1: Randomly pick initial cluster centers (centroids) from within the range of our data.\n",
    "        # This makes self.centroids a (k, n_features) array of points between the min and max value of X.\n",
    "        # To help you understand what this code does, let's use a real example.\n",
    "        # Suppose X is a set of points like:\n",
    "        # X = np.array([[1, 2], [2, 3], [3, 2], [8, 7], [7, 8], [8, 8]])\n",
    "        # X.min() = 1, X.max() = 8, so centroids are initialized as random points in [1, 8] for each feature.\n",
    "        # For 2 clusters (k=2) in 2D:\n",
    "        # self.centroids = np.random.uniform(1, 8, (2, 2))\n",
    "        # Example output for centroids could be:\n",
    "        # array([[6.25, 3.41],\n",
    "        #        [2.17, 7.88]])\n",
    "        #\n",
    "        # This initialization spreads out k random points across the full data range before fitting.\n",
    "        self.centroids = np.random.uniform(X.min(), X.max(), (self.k, n_features))\n",
    "\n",
    "        # Store history for visualization\n",
    "        self.centroid_history = [self.centroids.copy()]\n",
    "\n",
    "        for iteration in range(self.max_iters):\n",
    "            # Step 2: Assign points to closest centroid\n",
    "            distances = self._calculate_distances(X)\n",
    "            self.labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Step 3: Update centroids\n",
    "            new_centroids = np.zeros((self.k, n_features))\n",
    "            for i in range(self.k):\n",
    "                if np.sum(self.labels == i) > 0:  # Avoid empty clusters\n",
    "                    new_centroids[i] = X[self.labels == i].mean(axis=0)\n",
    "                else:\n",
    "                    new_centroids[i] = self.centroids[i]  # Keep old centroid\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.allclose(self.centroids, new_centroids):\n",
    "                print(f\"‚úÖ Converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "            self.centroid_history.append(self.centroids.copy())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _calculate_distances(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate Euclidean distances from points to centroids.\"\"\"\n",
    "        distances = np.zeros((X.shape[0], self.k))\n",
    "        for i, centroid in enumerate(self.centroids):\n",
    "            distances[:, i] = np.sqrt(np.sum((X - centroid) ** 2, axis=1))\n",
    "        return distances\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict cluster labels for new data points.\"\"\"\n",
    "        distances = self._calculate_distances(X)\n",
    "        return np.argmin(distances, axis=1)\n",
    "\n",
    "    def inertia_(self) -> float:\n",
    "        \"\"\"Calculate within-cluster sum of squares (WCSS).\"\"\"\n",
    "        wcss = 0\n",
    "        for i in range(self.k):\n",
    "            cluster_points = self.X[self.labels == i] if hasattr(self, 'X') else []\n",
    "            if len(cluster_points) > 0:\n",
    "                wcss += np.sum((cluster_points - self.centroids[i]) ** 2)\n",
    "        return wcss\n",
    "\n",
    "print(\" K-Means class implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_generation"
   },
   "source": [
    "## üìä Generate Sample Data\n",
    "\n",
    "Let's create some sample data with clear clusters to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "def generate_sample_data() -> np.ndarray:\n",
    "    \"\"\"Generate sample 2D data with clear clusters.\"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Create 3 clusters\n",
    "    cluster1 = np.random.normal([2, 2], [0.5, 0.5], (30, 2))\n",
    "    cluster2 = np.random.normal([6, 6], [0.5, 0.5], (30, 2))\n",
    "    cluster3 = np.random.normal([2, 6], [0.5, 0.5], (30, 2))\n",
    "\n",
    "    return np.vstack([cluster1, cluster2, cluster3])\n",
    "\n",
    "# Generate the data\n",
    "X = generate_sample_data()\n",
    "print(f\" Generated {len(X)} data points with 2 features\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Data range: X-axis [{X[:, 0].min():.2f}, {X[:, 0].max():.2f}], Y-axis [{X[:, 1].min():.2f}, {X[:, 1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## üìä Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz_functions"
   },
   "outputs": [],
   "source": [
    "def visualize_kmeans(X: np.ndarray, kmeans: KMeans, title: str = \"K-Means Clustering\"):\n",
    "    \"\"\"Visualize K-Means clustering results.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "    # Plot data points\n",
    "    for i in range(kmeans.k):\n",
    "        cluster_points = X[kmeans.labels == i]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "                   c=colors[i], alpha=0.6, label=f'Cluster {i+1}', s=50)\n",
    "\n",
    "    # Plot centroids\n",
    "    plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],\n",
    "               c='black', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Feature 1', fontsize=14)\n",
    "    plt.ylabel('Feature 2', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_original_data(X: np.ndarray):\n",
    "    \"\"\"Plot the original data without clustering.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c='gray', alpha=0.6, s=50)\n",
    "    plt.title('Original Data (Before Clustering)', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Feature 1', fontsize=14)\n",
    "    plt.ylabel('Feature 2', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "print(\" Visualization functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "original_data_viz"
   },
   "source": [
    "## üëÄ Let's Look at Our Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_original"
   },
   "outputs": [],
   "source": [
    "# Plot the original data\n",
    "plot_original_data(X)\n",
    "print(\"Can you see natural clusters forming? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run_kmeans"
   },
   "source": [
    "## üöÄ Run K-Means Clustering\n",
    "\n",
    "Now let's apply our K-Means algorithm to find the clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apply_kmeans"
   },
   "outputs": [],
   "source": [
    "# Apply K-Means\n",
    "print(\"üéØ Applying K-Means with k=3...\")\n",
    "kmeans = KMeans(k=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(f\"\\n Final centroids:\")\n",
    "for i, centroid in enumerate(kmeans.centroids):\n",
    "    print(f\"  Cluster {i+1}: ({centroid[0]:.2f}, {centroid[1]:.2f})\")\n",
    "\n",
    "print(f\"\\n Cluster assignments:\")\n",
    "unique, counts = np.unique(kmeans.labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster+1}: {count} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_viz"
   },
   "source": [
    "## üé® Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "visualize_kmeans(X, kmeans, \"K-Means Clustering Results (k=3)\")\n",
    "print(\" Beautiful clustering! Notice how the algorithm found the natural groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "predictions"
   },
   "source": [
    "## üîÆ Making Predictions on New Data\n",
    "\n",
    "Now let's use our trained model to predict which cluster new points belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_new"
   },
   "outputs": [],
   "source": [
    "# Example of predicting new points\n",
    "print(\" Predicting clusters for new points...\")\n",
    "new_points = np.array([[1, 1], [7, 7], [3, 5], [2.5, 2.5]])\n",
    "predictions = kmeans.predict(new_points)\n",
    "\n",
    "print(\"\\n Predictions:\")\n",
    "for i, (point, pred) in enumerate(zip(new_points, predictions)):\n",
    "    print(f\"  Point {point} ‚Üí Cluster {pred + 1}\")\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "# Plot original clustered data\n",
    "for i in range(kmeans.k):\n",
    "    cluster_points = X[kmeans.labels == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "               c=colors[i], alpha=0.6, label=f'Cluster {i+1}', s=50)\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],\n",
    "           c='black', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "\n",
    "# Plot new predictions\n",
    "for i, (point, pred) in enumerate(zip(new_points, predictions)):\n",
    "    plt.scatter(point[0], point[1], c=colors[pred], marker='*', \n",
    "               s=300, edgecolors='black', linewidths=2, \n",
    "               label=f'New Point {i+1}' if i == 0 else \"\")\n",
    "    \n",
    "    # Add text annotation\n",
    "    plt.annotate(f'New {i+1}', (point[0], point[1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontweight='bold')\n",
    "\n",
    "plt.title('K-Means: Original Clusters + New Predictions', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Feature 1', fontsize=14)\n",
    "plt.ylabel('Feature 2', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\" New points are marked with stars and predicted cluster colors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "experiment"
   },
   "source": [
    "## üß™ Experiment: Different Values of K\n",
    "\n",
    "Let's see what happens when we use different numbers of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "different_k"
   },
   "outputs": [],
   "source": [
    "# Test different K values\n",
    "k_values = [2, 3, 4, 5]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, k in enumerate(k_values):\n",
    "    # Apply K-Means with different k\n",
    "    kmeans_k = KMeans(k=k, random_state=42)\n",
    "    kmeans_k.fit(X)\n",
    "    \n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "    \n",
    "    # Plot data points\n",
    "    for i in range(k):\n",
    "        cluster_points = X[kmeans_k.labels == i]\n",
    "        axes[idx].scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "                         c=colors[i], alpha=0.6, label=f'Cluster {i+1}', s=50)\n",
    "    \n",
    "    # Plot centroids\n",
    "    axes[idx].scatter(kmeans_k.centroids[:, 0], kmeans_k.centroids[:, 1],\n",
    "                     c='black', marker='x', s=150, linewidths=3)\n",
    "    \n",
    "    axes[idx].set_title(f'K-Means with K={k}', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Feature 1')\n",
    "    axes[idx].set_ylabel('Feature 2')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" Which K value looks best to you? K=3 seems to match the natural clusters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## üìö Summary & Key Takeaways\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **K-Means Algorithm Steps:**\n",
    "   - Initialize K random centroids\n",
    "   - Assign points to closest centroid\n",
    "   - Update centroids to cluster centers\n",
    "   - Repeat until convergence\n",
    "\n",
    "2. **Key Properties:**\n",
    "   - Always converges to a solution\n",
    "   - Minimizes Within-Cluster Sum of Squares (WCSS)\n",
    "   - Creates Voronoi partitions\n",
    "\n",
    "3. **Important Considerations:**\n",
    "   - Need to choose K beforehand\n",
    "   - Sensitive to initialization\n",
    "   - Assumes spherical clusters\n",
    "   - Works best with similar-sized clusters\n",
    "\n",
    "### Next Steps:\n",
    "- Try the \"Find Optimal K\" methods (Elbow, Silhouette Analysis)\n",
    "- Experiment with real datasets\n",
    "- Compare with scikit-learn's implementation\n",
    "- Explore other clustering algorithms (DBSCAN, Hierarchical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sklearn_comparison"
   },
   "source": [
    "## üîç Bonus: Compare with Scikit-learn\n",
    "\n",
    "Let's compare our implementation with the professional one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sklearn_compare"
   },
   "outputs": [],
   "source": [
    "# Install scikit-learn if not available (uncomment next line if needed)\n",
    "# !pip install scikit-learn\n",
    "\n",
    "from sklearn.cluster import KMeans as SklearnKMeans\n",
    "\n",
    "# Apply sklearn K-Means\n",
    "sklearn_kmeans = SklearnKMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "sklearn_labels = sklearn_kmeans.fit_predict(X)\n",
    "sklearn_centroids = sklearn_kmeans.cluster_centers_\n",
    "\n",
    "# Compare results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "# Our implementation\n",
    "for i in range(3):\n",
    "    cluster_points = X[kmeans.labels == i]\n",
    "    ax1.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "               c=colors[i], alpha=0.6, label=f'Cluster {i+1}', s=50)\n",
    "ax1.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],\n",
    "           c='black', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "ax1.set_title('Our K-Means Implementation', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Feature 1', fontsize=14)\n",
    "ax1.set_ylabel('Feature 2', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Sklearn implementation\n",
    "for i in range(3):\n",
    "    cluster_points = X[sklearn_labels == i]\n",
    "    ax2.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "               c=colors[i], alpha=0.6, label=f'Cluster {i+1}', s=50)\n",
    "ax2.scatter(sklearn_centroids[:, 0], sklearn_centroids[:, 1],\n",
    "           c='black', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "ax2.set_title('Scikit-learn K-Means', fontsize=16, fontweight='bold')\n",
    "ax2.set_xlabel('Feature 1', fontsize=14)\n",
    "ax2.set_ylabel('Feature 2', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéØ Both implementations should give very similar results!\")\n",
    "print(f\"Our centroids:\\n{kmeans.centroids}\")\n",
    "print(f\"\\nSklearn centroids:\\n{sklearn_centroids}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
